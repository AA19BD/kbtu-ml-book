{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3064898-d081-4dec-85ae-ec5c8391a096",
   "metadata": {},
   "source": [
    "# Bayesian inference\n",
    " \n",
    " Bayesian inference is a way of reasoning that combines prior knowledge and data to estimate the probability of a hypothesis. In the Bayesian model, prior knowledge is understood as what you already know or believe about a situation based on your experience, expertise, or assumptions. On the other hand, data is new evidence that you collect as a result of observations, experiments, or surveys. The probability of a hypothesis is how likely it is to be true, considering both the prior knowledge and data.\n",
    "\n",
    "Bayesian inference consists of three steps.\n",
    "\n",
    "1. We choose a probability density function to model the parameter $θ$, that is, the a prior distribution $p(θ)$ . This is our best guess on the parameters before we get the data $X$.\n",
    "\n",
    "2. Probability function We choose a probability density function for $p(X|θ)$ . Essentially we are modeling how the data X will look like with the given parameter $θ$ .\n",
    "\n",
    "3. Posterior probability We compute the posterior distribution $p(θ|X)$ and choose the $θ$ with the highest $p(θ|X)$ .\n",
    "\n",
    "As a result, the posterior distribution becomes the new a prior distribution. The third step needs to be repeated each time new data arrives.\n",
    "\n",
    "## Mathematical equation of Bayesian Inference\n",
    "\n",
    "Bayesian inference uses a mathematical formula called Bayes' theorem to update the probability of a hypothesis as new data becomes available.\n",
    "\n",
    "$$ \n",
    "{p(θ|X)} = \\frac{p(X|\\theta)\\times p(\\theta)} {p(X)}\n",
    "$$\n",
    "\n",
    "where  \n",
    "\n",
    "$p(X|θ)$ - the likelihood, that is, the distribution of the observed data $X$ conditional on the parameter $θ$;\n",
    "\n",
    "$p(θ)$ - the prior distribution;\n",
    "\n",
    "$p(θ|X)$ - the posterior distribution.\n",
    "\n",
    "\n",
    " Bayesian inference has 3 basic blocks and these are:\n",
    " \n",
    " #### *The likelihood*\n",
    "\n",
    " The first building block of a  parametric  of Bayesian inference is likehood:\n",
    "$$\n",
    "\\boldsymbol p(X|θ)\n",
    "$$\n",
    "When the paramters of the distribution generated by the data are equal to $θ$, the probability density of $X$.\n",
    "\n",
    "No we assume that $X$ and $θ$ are continous. We will discuss later how to relax this assumption.\n",
    "\n",
    "#### *The prior*\n",
    "\n",
    "The second building block our inference is the prior:\n",
    "$$\n",
    "\\boldsymbol p(θ)\n",
    "$$\n",
    "The prior is the subjective probability density associated with the parameter $θ$\n",
    "\n",
    "#### *The posterior*\n",
    "\n",
    "After obseving data $X$, we operate Bayes' rule to update the prior about the parameter $θ$ (the formula is given below)\n",
    "\n",
    "Suppose that we fit a model with parameters $\\boldsymbol w$ to the dataset $\\boldsymbol D = (\\boldsymbol X, \\boldsymbol y)$. According to the Bayes formula the posterior distribution:\n",
    "\n",
    "$$\n",
    "    p(\\boldsymbol w \\vert \\boldsymbol X, \\boldsymbol y) \\propto p(\\boldsymbol y \\vert \\boldsymbol X, \\boldsymbol w) p(\\boldsymbol w).\n",
    "$$\n",
    "\n",
    "We are particularly interested in the posterior distribution because it allows us to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Distribution functions in dynamic graph\n",
    "source: https://www.datacamp.com/tutorial/probability-distributions-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, widgets\n",
    "from scipy.stats import uniform, norm, expon, bernoulli, binom, poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_graph(distribution_type, parameter_1, parameter_2):\n",
    "    x = np.linspace(0, 1, 1000) # theta\n",
    "\n",
    "    if distribution_type == 'Uniform':\n",
    "        # x = 1000 # theta\n",
    "        y = uniform.pdf(x, loc=parameter_1, scale=parameter_2)\n",
    "        title = f\"Uniform distribution: start={parameter_1}, width{parameter_2}\"\n",
    "    elif distribution_type == 'Normal':\n",
    "        y = norm.pdf(x, loc=parameter_1, scale=parameter_2)\n",
    "        title = f\"Normal distribution: mean of the distribution={parameter_1}, standard deviation={parameter_2}\"\n",
    "    elif distribution_type == 'Exponential':\n",
    "        y = expon.pdf(x, loc=parameter_1, scale=parameter_2)\n",
    "        title = f\"Exponential distribution: loc={parameter_1}, 1/lambda={parameter_2}\"\n",
    "    elif distribution_type == 'Bernouli':\n",
    "        y = bernoulli.pmf(x, p=parameter_1)\n",
    "        title = f\"Bernouli distribution: probability of success={parameter_1} (<= 1)\"\n",
    "    elif distribution_type == 'Binomial':\n",
    "        y = binom.pmf(x, n=int(parameter_1), p=parameter_2)\n",
    "        title = f\"Binomial distribution: n={int(parameter_1)}, probability of success=={parameter_2} (<= 1)\"\n",
    "    elif distribution_type == 'Poisson':\n",
    "        y = poisson.pmf(x, mu=int(parameter_1))\n",
    "        title = f\"Poisson distribution: lambda={int(parameter_1)}\"\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.plot(x, y, label=distribution_type)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Theta')\n",
    "    plt.ylabel('')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "choose_dist_type = widgets.Dropdown(\n",
    "    options=['Uniform', 'Normal', 'Exponential', 'Bernouli', 'Binomial', 'Poisson'],\n",
    "    value='Uniform',\n",
    "    description='Distribution type:'\n",
    ")\n",
    "\n",
    "parameter_1 = widgets.FloatSlider(value=0, min=0, max=10, step=0.1, description='Parameter 1')\n",
    "parameter_2 = widgets.FloatSlider(value=1, min=0, max=10, step=0.1, description='Parameter 2')\n",
    "\n",
    "\n",
    "interact_plot = interact(\n",
    "    generate_graph,\n",
    "    distribution_type=choose_dist_type,\n",
    "    parameter_1 = parameter_1,\n",
    "    parameter_2 = parameter_2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjugate distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In probabilistic theory, if the prior and the posterior belong to the same parametric family (set of probability distributions that share a common mathematical form or structure characterized by a set of parameters), then the prior is considered conjugate for the likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(θ|x) = \\frac{p(x|θ)p(θ)}{p(x)} = \\frac{p(x|θ)p(θ)}{\\int_{θ}^{} p(x|θ)p(θ)dθ}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $Φ $ be a parametric family of probability distributions. A prior distribution $p(θ)$ belonging to $Φ $ is said to be conjugate for the likelihood $p(x|θ)$ if and only if, the resulting posterior distribution $p(θ|x)$ also belongs to $Φ $ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, this can be expressed as:\n",
    "$$\n",
    "p(θ|x) \\in Φ \\text{  if and only if  } (θ) \\in Φ \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In symbols:\n",
    "$$\n",
    "p(θ|x) \\in Φ \\Leftrightarrow p(θ) \\in Φ\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple words, when we use a conjugate prior, the updated posterior obtained through Bayesian updating process belongs to the same parametric family as the prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial likelihood and beta priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click to show\n",
    "Remark\n",
    "Reminder -  click/hide intercation with user\n",
    "\n",
    "\n",
    "Remark: The Binomial distribution represents the probability of obtaining a number of successes in a fixed number of independent trials, where each trial has a binary outcome (success/failure) with probability $p$ of success. The Beta distribution is a continuous probability distribution defined on the interval [0,1], often parametrized by two shape parameters, $ \\alpha $ and $ \\beta $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````{admonition} Remark :class: dropdown \n",
    "\n",
    "The Binomial distribution represents the probability of obtaining a number of successes in a fixed number of independent trials, where each trial has a binary outcome (success/failure) with probability $p$ of success. The Beta distribution is a continuous probability distribution defined on the interval [0,1], often parametrized by two shape parameters, $ \\alpha $ and $ \\beta $.\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x | n, \\alpha , \\beta) = \\int_{0}^{1} Bin(x|n,p)Beta(p|\\alpha,\\beta){ dp} \n",
    "= {\\left(\\begin{array}{c}n\\\\ x\\end{array}\\right)}{\\frac{1}{B(\\alpha, \\beta)}}\\int_{0}^{1} p^{x+\\alpha-1} {(1-p)^{n-x+\\beta-1}}dp\n",
    "={\\left(\\begin{array}{c}n\\\\ x\\end{array}\\right)}{\\frac{ B(x+\\alpha, n-x+ \\beta)}{B(\\alpha, \\beta)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or like this\n",
    "1. Prior distribution:\n",
    "<br>\n",
    "$p(p) \\propto p^{\\alpha - 1} \\cdot (1-p)^{\\beta-1}$\n",
    "\n",
    "2. Likelihood function\n",
    "<br>\n",
    "$p(X=k|p) = {\\left(\\begin{array}{c}n\\\\ k\\end{array}\\right)} \\cdot p^k \\cdot (1-p)^{n-k}$\n",
    "<br>\n",
    "where the $k$ is a fixed number of independent trials\n",
    "\n",
    "3. Posterior distribution\n",
    "<br>\n",
    "$p(p|X=k) \\propto p^{\\alpha + k - 1} \\cdot (1-p)^{\\beta+n-k-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beta-binomial model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with soccer dataset https://www.kaggle.com/datasets/irkaal/english-premier-league-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta, binom\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the data. The main columns that we'll work are **Season** and **FTR = Full Time Result (H=Home Win, D=Draw, A=Away Win)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset_for_bayes_inference/results.csv\", encoding='latin-1')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will select matches of Home Teams (local teams) from 2015 season to 2020 and try to observe new data which will be matches from 2020-2021 season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_matches = df.query(\"Season in ['2015-16', '2016-17','2017-18', '2018-19', '2019-20']\")\n",
    "selected_matches_number = len(selected_matches)\n",
    "print(\"Seasons from 2015 to 2020: \",selected_matches_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a prior belief will be a win rate of the selected matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_wins = len(selected_matches[selected_matches['FTR'] == 'H'])\n",
    "home_win_rate = round(home_wins/selected_matches_number,2)\n",
    "print(\"Win rate: \", home_win_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha$ and $\\beta$ positive parameters control the shape of the distribution. Prior parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_param = home_win_rate * selected_matches_number\n",
    "beta_param = selected_matches_number - alpha_param\n",
    "\n",
    "print(alpha_param, beta_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected matches from 2020 to 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_matches_20_21 = df.query(\"Season == '2020-21'\")\n",
    "selected_matches_20_21_num = len(selected_matches_20_21)\n",
    "\n",
    "home_wins_20_21 = len(selected_matches_20_21[selected_matches_20_21['FTR'] == 'H'])\n",
    "win_rate_20_21 = round(home_wins_20_21/selected_matches_20_21_num,2)\n",
    "\n",
    "print(\" Selected matches from 2020-21: \", selected_matches_20_21_num, \"\\n\", \"Win matches: \", home_wins_20_21, \"\\n\", \"Win rate: \", win_rate_20_21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to eq10, the posterior parameters are:\n",
    "\n",
    "$$ \\alpha’ = \\alpha + y $$\n",
    "$$ \\beta’ = n - y + \\beta$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_pos_param = alpha_param + home_wins_20_21\n",
    "beta_pos_param = selected_matches_20_21_num - home_wins_20_21 + beta_param\n",
    "print(alpha_pos_param, beta_pos_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets calculate prior, likelihood and posterior of our selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = selected_matches_20_21_num\n",
    "y = home_wins_20_21\n",
    "\n",
    "theta = np.linspace(0,1,1000) # parameter array represents a possible value of the parameter for the beta distribution\n",
    "\n",
    "prior = beta.pdf(theta, alpha_param, beta_param)\n",
    "likelihood = binom.pmf(y, n, theta) \n",
    "posterior = beta.pdf(theta, alpha_pos_param, beta_pos_param) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot representation of results of Bayesian upfate theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_show(theta, prior, likelihood, posterior, l_factor):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.plot(theta, prior, label=\"prior\")\n",
    "    ''' \n",
    "    l_factor for scaling the likelihood curve to distinguish the \n",
    "    likelihood curve from the prior and posterior curves in the plot\n",
    "    Because likelihood function typically has a smaller curve.\n",
    "    But scaling the likelihood function isn't required by math.\n",
    "    '''\n",
    "    plt.plot(theta, l_factor * likelihood, label=\"likelihood\")\n",
    "    plt.plot(theta, posterior, label=\"posterior\")\n",
    "\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.xticks(np.arange(0, 1, 0.1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_show(theta, prior, likelihood, posterior, l_factor=900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing the graph we can observe that the blue line describes our prior belief which is more than 0.4 on x-axis (we already defined this value as 0.46), likelihood function shown as an orange curve has highest probability value less than 0.4, and posterior's green curve is around 0.45 after seeing our data from 2020 to 2021. <br> The posterior' value is less than our prior belief which means that **the probability changed** after observing the new data. Now our local teams have a winning probability of around 0.45."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uninformative value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we don't consider the prior belief of our data? On the previous example a prior belief was calculated from the matches between 2015-2020. New data were from 2020-2021. We know that during this period was COVID-19 and maybe this affected to our players. <br> <br> Calculating with minimal prior belief called **uninformative prior**. Uniformative prior has equal weights for all possible values of the parameter. This means that all values of the parameter are equally likely before we see any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_param = 1\n",
    "beta_param = 1\n",
    "\n",
    "alpha_pos_param = alpha_param + y\n",
    "beta_pos_param = n - y + beta_param\n",
    "\n",
    "prior = beta.pdf(theta, alpha_param, beta_param)\n",
    "likelihood = binom.pmf(y, n, theta) \n",
    "posterior = beta.pdf(theta, alpha_pos_param, beta_pos_param) \n",
    "\n",
    "plot_show(theta, prior, likelihood, posterior, l_factor=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After observing our data in the graph we can see 3 lines. Our prior blue line is flat which means all values of the parameter are equally likely before seeing any data. The likelihood orange curve has a value around 0.4 (or less than 0.4). The same value can be observed in the posterior green curve but it is more spread out than the likelihood function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The normal likelihood and normal priors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we considering a normal likelihood and a normal prior in Bayesian statistics, we're essentially dealing with a situation where both the likelihood and the prior distributions follow the normal (Gaussian) distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal parametric family has two parameters - the mean $μ$ and the variance​ $σ^2$, so The Bayesian updating process with a normal likelihood and normal prior can be expressed as follows:\n",
    " \n",
    "$$\n",
    "p(μ|x) = (2 \\pi \\tau_n^2)^{-\\frac{1}{2}} \\exp{(-\\frac{1}{2\\tau_n^2} (μ-μ_n)^2)}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "μ_n = (\\frac{n}{σ^2} + \\frac{1}{\\tau_0^2})^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or like this:\n",
    "\n",
    "1. Prior distribution:\n",
    "<br>\n",
    "$p(θ) \\propto \\exp{(- \\frac{1}{2σ_2^0} (θ-μ_0)^2)}$\n",
    "\n",
    "2. Likelihood function\n",
    "<br>\n",
    "$p(X=x|θ) \\propto \\exp{(- \\frac{1}{2σ^2} (x-θ)^2)}$\n",
    "\n",
    "3. Posterior distribution\n",
    "<br>\n",
    "$p(θ|X=x) \\propto \\exp{(- \\frac{1}{2σ_n^2}(θ - μ_n)^2)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Code Daulet ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, it is also known as the \"bell-shaped distribution\" due to the resemblance of its probability density function graph to the shape of a bell."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
